# DNN

## 369 MLP
369 게임을 다층 퍼셉트론으로 구현


## gradient
활성화 함수와 Gradient 학습
sigmoid, ReLU, FC Layer, MSE Loss 
활성화 함수 별로 성능을 비교
model 폴더의 model.py 파일에 sigmoid, ReLU, FC Layer, MSE Loss 각 함수의 gradient 계산 방법을 구현하였음

Function 1 (𝑦 = 0.3𝑥^2ㄴ + 0.13𝑥 + 5)
<img src="https://user-images.githubusercontent.com/79688191/145775487-f6b8ba9b-1341-4bf7-b9d9-3d14b6f9c33b.png"  width="300" height="300"/>


<img src="https://user-images.githubusercontent.com/79688191/145775550-8aa75f34-0c46-470b-820d-65d427549f0c.png" width="300" height="300"/>

Function 2 (𝑦 = 0.5𝑥1^2 − 0.2𝑥1𝑥2 − 0.3𝑥2^2 + 0.4𝑥2 + 10) 

<img src="https://user-images.githubusercontent.com/79688191/145775655-357288ec-8297-4246-bc30-42cde1a4f1d9.png" width="300" height="300"/>
<img src="https://user-images.githubusercontent.com/79688191/145775721-8ff89905-32d8-42f9-b08b-c77f0bb37ff3.png" width="300" height="300"/>


Function 3 (𝑦 = 𝑠𝑖𝑛(𝑥)𝑐𝑜𝑠(𝑥) + 1)

<img src="https://user-images.githubusercontent.com/79688191/145775770-a513a499-ca40-44fd-9a22-abbfdcca6863.png" width="300" height="300"/>
<img src="https://user-images.githubusercontent.com/79688191/145775829-97b3959c-399c-4cdf-a4b4-2cb988b7148a.png" width="300" height="300"/>
